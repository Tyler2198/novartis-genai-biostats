{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# === 1. Setup ===\n",
    "def load_and_prepare(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = splitter.split_documents(docs)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = Chroma.from_documents(splits, embedding=embeddings)\n",
    "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# === 2. Prompt Variants ===\n",
    "basic_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant for medical affairs.\n",
    "\n",
    "Use the following context to answer the question concisely and accurately.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "cot_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a biomedical research assistant.\n",
    "\n",
    "Use the following context to answer the question, reasoning step by step.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Let's think through this:\n",
    "\"\"\")\n",
    "\n",
    "few_shot_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a biomedical assistant. Here is how you should respond.\n",
    "\n",
    "Example:\n",
    "\n",
    "Question: What is the role of real-world data in clinical studies?\n",
    "\n",
    "Answer:\n",
    "Real-world data helps identify population-level patterns outside of clinical trials. It supports regulatory decisions and comparative effectiveness studies.\n",
    "\n",
    "Now answer this:\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "# === 3. Build chain ===\n",
    "def build_chain(prompt_template, retriever):\n",
    "    llm = ChatOllama(model=\"llama3\")\n",
    "    return (\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "# === 4. Main Interactive App ===\n",
    "def main():\n",
    "    retriever = load_and_prepare(\"/Users/kryptonempyrean/Desktop/TS3043166.pdf\")\n",
    "\n",
    "    options = {\n",
    "        \"1\": (\"Basic Prompt\", basic_prompt),\n",
    "        \"2\": (\"Chain-of-Thought Prompt\", cot_prompt),\n",
    "        \"3\": (\"Few-Shot Prompt\", few_shot_prompt)\n",
    "    }\n",
    "\n",
    "    print(\"ðŸ§  Choose prompt style:\")\n",
    "    for key, (name, _) in options.items():\n",
    "        print(f\"{key}. {name}\")\n",
    "\n",
    "    choice = input(\"Your choice (1/2/3): \").strip()\n",
    "    if choice not in options:\n",
    "        print(\"Invalid choice.\")\n",
    "        return\n",
    "\n",
    "    prompt_name, prompt_template = options[choice]\n",
    "    print(f\"âœ… Using: {prompt_name}\")\n",
    "\n",
    "    chain = build_chain(prompt_template, retriever)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"ðŸ§  You: \")\n",
    "        if query.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "        response = chain.invoke(query)\n",
    "        print(\"\\nðŸ¤– Bot:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
